{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP5+dgQPSL/rvHSQDvvQrnA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OhAfu1ll-4Bh","executionInfo":{"status":"ok","timestamp":1738840764454,"user_tz":-330,"elapsed":27866,"user":{"displayName":"sumitha2 jella2","userId":"08584096067352563231"}},"outputId":"14435b01-f90d-4031-8654-931fed684bd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import pandas as pd\n","from transformers import XLNetTokenizer, XLNetForSequenceClassification, get_scheduler\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader, Dataset\n","from torch.cuda.amp import autocast, GradScaler\n","\n","# Check if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Load the dataset\n","file_path = \"/content/drive/My Drive/emotion_dataset.csv\"  # Adjust your file path\n","df = pd.read_csv(file_path)\n","\n","# Display first few rows\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NyV_BuRD-5VR","executionInfo":{"status":"ok","timestamp":1738841892044,"user_tz":-330,"elapsed":2757,"user":{"displayName":"sumitha2 jella2","userId":"08584096067352563231"}},"outputId":"c62ffdac-2756-4bb8-baa3-ba6de83a597e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","   Unnamed: 0                                               text Emotion\n","0           0  i seriously hate one subject to death but now ...    hate\n","1           3  ive been really angry with him and i feel like...   anger\n","2           5  i feel jealous becasue i wanted that kind of l...    love\n","3           7  i finally fell asleep feeling angry useless an...   worry\n","4          15               i feel like they hated me since then    hate\n"]}]},{"cell_type":"code","source":["# Encode emotion labels\n","emotion_labels = df[\"Emotion\"].unique().tolist()\n","label_to_id = {label: idx for idx, label in enumerate(emotion_labels)}\n","df[\"label\"] = df[\"Emotion\"].map(label_to_id)\n","\n","# Split dataset\n","train_texts, test_texts, train_labels, test_labels = train_test_split(\n","    df[\"text\"].tolist(), df[\"label\"].tolist(), test_size=0.2, random_state=42\n",")\n","\n","# Load XLNet tokenizer\n","tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n","\n","# Define dataset class\n","class EmotionDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len=128):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","        encoding = self.tokenizer(\n","            text, padding=\"max_length\", truncation=True, max_length=self.max_len, return_tensors=\"pt\"\n","        )\n","        return {\n","            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n","            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n","            \"label\": torch.tensor(label, dtype=torch.long),\n","        }\n","\n","# Create datasets and dataloaders\n","train_dataset = EmotionDataset(train_texts, train_labels, tokenizer)\n","test_dataset = EmotionDataset(test_texts, test_labels, tokenizer)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n","\n","# Load XLNet model\n","model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=len(emotion_labels))\n","model.to(device)\n","\n","# Define optimizer, loss function, and scheduler\n","optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","num_training_steps = len(train_loader) * 3  # Assuming 3 epochs\n","lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n","\n","scaler = GradScaler()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eWDz66NR_LuB","executionInfo":{"status":"ok","timestamp":1738841897572,"user_tz":-330,"elapsed":2324,"user":{"displayName":"sumitha2 jella2","userId":"08584096067352563231"}},"outputId":"b7a7e3ca-b4ad-44d0-c3a2-faa90c6b6a65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","<ipython-input-6-71a49ccd92f9>:55: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n"]}]},{"cell_type":"code","source":["# Training function with AMP\n","def train(model, train_loader, optimizer, loss_fn, epochs=1):\n","    model.train()\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for batch in train_loader:\n","            optimizer.zero_grad()\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            labels = batch[\"label\"].to(device)\n","\n","            with autocast():\n","                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","                loss = outputs.loss  # Directly get loss from model\n","\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","            lr_scheduler.step()\n","\n","            total_loss += loss.item()\n","\n","        avg_loss = total_loss / len(train_loader)\n","        print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n","\n","# Train model\n","train(model, train_loader, optimizer, loss_fn)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yb_C_2At_R60","executionInfo":{"status":"ok","timestamp":1738843582330,"user_tz":-330,"elapsed":1680173,"user":{"displayName":"sumitha2 jella2","userId":"08584096067352563231"}},"outputId":"20a5a8fa-74c0-4b91-d850-653e94027e26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-871e4104f4a1>:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast():\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.0961\n"]}]},{"cell_type":"code","source":["def evaluate(model, data_loader):\n","    model.eval()  # Set the model to evaluation mode\n","    total_correct = 0\n","    total_examples = 0\n","\n","    with torch.no_grad():  # No need to compute gradients for evaluation\n","        for batch in data_loader:\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            labels = batch[\"label\"].to(device)\n","\n","            # Get model outputs\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","\n","            # Choose the class with the highest logit as prediction\n","            predictions = torch.argmax(logits, dim=1)\n","\n","            # Update the count of correct predictions and total examples\n","            total_correct += (predictions == labels).sum().item()\n","            total_examples += labels.size(0)\n","\n","    # Calculate accuracy\n","    accuracy = total_correct / total_examples\n","    return accuracy\n","\n","# Evaluate the model on the test set\n","test_accuracy = evaluate(model, test_loader)\n","print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"],"metadata":{"id":"9gJe731T_1PI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738844240284,"user_tz":-330,"elapsed":37870,"user":{"displayName":"sumitha2 jella2","userId":"08584096067352563231"}},"outputId":"d87ea63b-3c71-41ec-f922-ea40be46347c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.9976\n"]}]},{"cell_type":"code","source":["# Save the model to Google Drive\n","model_save_path = \"/content/drive/My Drive/emotional_analysis.pt\"  # Path on your Google Drive\n","torch.save(model.state_dict(), model_save_path)\n","print(f\"Model saved to: {model_save_path}\")"],"metadata":{"id":"bcQ18yfo_TUR"},"execution_count":null,"outputs":[]}]}